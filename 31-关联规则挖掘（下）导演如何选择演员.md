# 31-关联规则挖掘（下）导演如何选择演员



### 如何使用 Apriori 工具包

```python
pip install efficient-apriori
```



`itemsets, rules = apriori(data, minn_support, min_confidence)`

data 是我们提供的数据集，它是一个list 数组类型，min_support 参数为最小支持度， 0-1 表示百分比,

min_confidence 是最小置信度，数值也代表百分比，比如 1 代表 100%



```python
from efficient_apriori import apriori

# 设置数据集

data = [('牛奶', '面包','尿布'),
       ('可乐', '面包','尿布','啤酒'),
       ('牛奶', '尿布','啤酒','鸡蛋'),
       ('面包', '牛奶','尿布','啤酒'),
       ('面包', '牛奶','尿布','可乐')]

# 挖掘频繁项集和频繁规则
itemsets, rules = apriori(data, min_support=0.5, min_confidence=1)

print(itemsets)
print(rules)

```

### 挖掘导演是如何选择演员的

webdriver chrome 爬虫下载数据

```python
# -*- coding: utf-8 -*-
from selenium import webdriver
from lxml import etree
import time
import csv

driver = webdriver.Chrome()
# 设置想要下载的导演，数据集
director = u'宁浩'
# 写csv文件
file_name = './' + director + '.csv'
base_url = 'https://movie.douban.com/subject_search?search_text=' + director + '&cat=1002&start='
out = open(file_name, 'w', newline='', encoding='utf-8-sig')
csv_write = csv.writer(out, dialect='excel')

# 下载指定页面的数据
def download(request_url):
    driver.get(request_url)
    time.sleep(1)
    html = driver.find_element_by_xpath('//*').get_attribute('outerHTML')
    html = etree.HTML(html)
    # 设置电影名称，导演演员的xpath
    movie_lists = html.xpath(
        "/html/body/div[@id='wrapper']/div[@id='root']/div[1]//div[@class='item-root']/div[@class='detail']/div[@class='title']/a[@class='title-text']")
    name_lists = html.xpath(
        "/html/body/div[@id='wrapper']/div[@id='root']/div[1]//div[@class='item-root']/div[@class='detail']/div[@class='meta abstract_2']")
    # 获取返回数据个数
    num = len(movie_lists)
    if num > 15: # 第一页会有16条数据，第一条为导演信息
        movie_lists = movie_lists[1:]
        name_lists = name_lists[1:]
    for (movie, name_list) in zip(movie_lists, name_lists):
        # 会存在数据为空的情况
        if name_list.text is None:
            continue
        # 显示演员名称
        print(name_list.text)
        names = name_list.text.split('/')
        # 判断导演是否为指定的director
        if names[0].strip() == director:
            # 将第一个字段设置为电影名称
            names[0] = movie.text
            csv_write.writerow(names)
    print('OK') # 代表这页下载吃呢公共
    if num >= 15:
        # 继续下一页
        return True
    else:
        # 没有下一页
        return False

# 开始ID为0，每页增加15
start = 0
while start < 10000: # 最多抽取10000部电影
    request_url = base_url + str(start)
    # 下载数据，并返回是否有下一页
    flag = download(request_url)
    if flag:
        start = start + 15
    else:
        break
out.close()
print('finished')
```

### apriori 算法分析

```python
df = pd.read_csv('./宁浩.csv', header=0, names=range(1,9))
# 将数据转化为列表形式输出
data = []
for index,row in df.iterrows():
    actor = []
    actor = row.tolist()
    actor = [i for i in actor if not pd.isnull(i)]
    data.append(actor)
#     for r in row:
#         if not pd.isnull(r):
#             actor.append(r)
#     data.append(actor)
data

itemsets, rules = apriori(data, min_support=0.5, min_confidence=1)
print(itemsets)
print(rules)
```

